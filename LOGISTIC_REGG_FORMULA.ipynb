{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cd679c",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL BUILDING ------>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1da73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logeg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "logeg.fit(di_train_x,di_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logeg.predict(di_test_x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = logeg.predict_proba(di_test_x)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb35f5",
   "metadata": {},
   "source": [
    "# confussion metrices ----->>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tab = confusion_matrix(pred,di_test_y)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97bfef5",
   "metadata": {},
   "source": [
    "# ACCURACY ---->>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred,di_test_y)*100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9deae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 SCORE,RECALL [DIRECT METHOD TO CALCULATE AALL THE PARAMETER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e92f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(di_test_y,pred)) # just to check =======>>>>>> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER METHOD TO CALCULATE THE ---->>> F1,RECALL AND PRECISION SEPARATELY ------>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c42419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score ---->>>\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(di_test_y,pred)\n",
    "\n",
    "#Recall ----->>>>\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(di_test_y,pred)\n",
    "\n",
    "# precision --->\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(di_test_y,pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e44ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR VS TPR ------>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd31efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_roc_auc=roc_auc_score(di_test_y,pred)\n",
    "log_roc_auc=round(log_roc_auc ,2) # Area under the curve\n",
    "log_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d88f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = logeg.predict_proba(di_test_x)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred_proba)   # converting it into data frame \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR VS TPR\n",
    "\n",
    "fpr,tpr,threshold = roc_curve(di_test_y,df.iloc[:,1])\n",
    "\n",
    "plt.plot(fpr,tpr,color = \"red\")\n",
    "plt.grid()\n",
    "plt.title(\"AUROC ON DIABETES \",size = 15)\n",
    "plt.xlabel(\"False postive ratio\", size = 15)\n",
    "plt.ylabel(\"True postive ratio\", size = 15)\n",
    "plt.text(x=.5,y=.5 ,s = \"Area under curve\", size = 15)\n",
    "plt.text(x=.5,y=.6 ,s = log_roc_auc, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022c747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f9a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME SERIES FORMULAES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to the check weather it works or not  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22064351",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit = auto_arima(ind_airpas_log.Passengers ,trace=True , suppress_warnings=True)\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ba54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6e3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a47f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\HADOOP_DATASET\\Loan_Approval_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4592029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b52a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
